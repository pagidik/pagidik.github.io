<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>3D Object Detection | Kishore Reddy Pagidi</title>
    <link rel="icon" href="data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 32 32'%3E%3Crect fill='%236366f1' width='32' height='32' rx='6'/%3E%3Ctext x='16' y='22' fill='white' font-family='Georgia,serif' font-size='16' font-weight='bold' text-anchor='middle'%3EKP%3C/text%3E%3C/svg%3E">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&family=Playfair+Display:wght@600;700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="assets/css/style.css">
    <style>
        .project-detail { padding: var(--space-5xl) 0; }
        .project-detail-header { margin-bottom: var(--space-3xl); }
        .project-detail-title { font-family: var(--font-display); font-size: clamp(2rem, 5vw, 3rem); margin-bottom: var(--space-lg); }
        .project-detail-meta { display: flex; flex-wrap: wrap; gap: var(--space-md); margin-bottom: var(--space-xl); }
        .project-detail-tag { padding: var(--space-xs) var(--space-md); background: var(--color-surface); border: 1px solid var(--color-border); border-radius: var(--radius-full); font-size: 0.875rem; }
        .project-detail-content { max-width: 800px; margin: 0 auto; }
        .project-detail-content h2 { font-family: var(--font-display); font-size: 1.75rem; margin: var(--space-3xl) 0 var(--space-lg); color: var(--color-text); }
        .project-detail-content h3 { font-size: 1.25rem; margin: var(--space-2xl) 0 var(--space-md); color: var(--color-text); }
        .project-detail-content p { margin-bottom: var(--space-lg); color: var(--color-text-secondary); line-height: 1.8; }
        .project-detail-content img { width: 100%; border-radius: var(--radius-lg); margin: var(--space-xl) 0; background: white; padding: 0.75rem; }
        .project-detail-content figure { margin: var(--space-2xl) 0; }
        .project-detail-content figcaption { text-align: center; font-size: 0.875rem; color: var(--color-text-muted); margin-top: var(--space-sm); }
        .back-link { display: inline-flex; align-items: center; gap: var(--space-sm); color: var(--color-primary); margin-bottom: var(--space-2xl); text-decoration: none; font-weight: 500; }
        .back-link:hover { text-decoration: underline; }
        .image-grid { display: grid; gap: var(--space-md); margin: var(--space-xl) 0; }
        .image-grid.cols-3 { grid-template-columns: repeat(auto-fit, minmax(250px, 1fr)); }
    </style>
</head>
<body>
    <nav class="nav" id="nav">
        <div class="container nav-container">
            <a href="index.html" class="nav-logo">KP</a>
            <ul class="nav-menu" id="nav-menu">
                <li><a href="index.html#about" class="nav-link">About</a></li>
                <li><a href="index.html#projects" class="nav-link">Work</a></li>
                <li><a href="index.html#research" class="nav-link">Research</a></li>
                <li><a href="index.html#writing" class="nav-link">Writing</a></li>
                <li><a href="index.html#contact" class="nav-link nav-link--cta">Get in Touch</a></li>
            </ul>
            <button class="nav-toggle" id="nav-toggle" aria-label="Toggle menu">
                <span></span><span></span><span></span>
            </button>
        </div>
    </nav>

    <main class="project-detail">
        <div class="container">
            <div class="project-detail-content">
                <a href="index.html#research" class="back-link">
                    <svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M19 12H5M12 19l-7-7 7-7"/></svg>
                    Back to Research
                </a>

                <header class="project-detail-header">
                    <h1 class="project-detail-title">3D Object Detection on LiDAR Point Cloud</h1>
                    <div class="project-detail-meta">
                        <span class="project-detail-tag">Autonomous Vehicles</span>
                        <span class="project-detail-tag">Deep Learning</span>
                        <span class="project-detail-tag">Computer Vision</span>
                    </div>
                </header>

                <img src="images/lidarOD/1.png" alt="3D Object Detection Overview">

                <h2>Introduction</h2>
                <p>Autonomous vehicles and robotics applications rely on accurate perception of their surroundings in order to navigate and perform tasks safely and effectively. One key aspect of perception is the ability to detect and classify objects in the environment. Traditional 2D object detection methods, which rely on image data from cameras, can be affected by occlusions and partial visibility of objects in complex and dynamic environments.</p>
                <p>LiDAR (Light Detection and Ranging) sensors offer an alternative approach for 3D object detection, as they generate 3D point cloud data using lasers that can provide more accurate localization and orientation estimation of objects.</p>
                <p>In this project, we propose a method for 3D object detection using lidar data in autonomous vehicles and robotics applications. Our approach involves representing the point cloud data in voxels, which are 3D grids that partition the data into small cubic cells, and a bird's eye view (BEV) representation, which projects the 3D data onto a 2D plane.</p>

                <figure>
                    <img src="images/3dobject/bev.png" alt="Bird's Eye View Representation">
                    <figcaption>Bird's Eye View (BEV) representation of LiDAR point cloud data</figcaption>
                </figure>

                <h2>Dataset</h2>
                <p>We evaluated our approach on the Lyft dataset, which contains real-world urban driving scenarios with both lidar and camera data. The dataset includes a variety of objects, such as vehicles, pedestrians, and traffic signs, in a range of challenging conditions, including occlusions and partial visibility.</p>
                <p>The organization of the data into "scenes" and "samples" allows for a clear understanding of the context in which the data was collected. The ego pose data, which includes the poses of the vehicle at specific timestamps, is also important for understanding the movement and positioning of the car within its environment.</p>

                <figure>
                    <img src="images/3dobject/classescount.png" alt="Class Distribution">
                    <figcaption>Distribution of object classes in the dataset</figcaption>
                </figure>

                <h2>Method</h2>
                <h3>Pre-Processing</h3>
                <p>Voxelization is the process of discretizing a continuous space into a set of discrete 3D cells or "voxels". In the case of lidar point cloud data, voxelization is used to create a 3D grid representation of the data, where each voxel contains a certain number of points within its volume.</p>
                <p>After voxelization, the point cloud data was converted into a bird's eye view (BEV) representation. BEV representation is a top-down view of the data, where the x and y axes correspond to the lateral dimensions of the scene and the z-axis corresponds to the height.</p>

                <h3>Network Architecture</h3>
                <p>The pre-processed point cloud data was then used to train a neural network using a supervised learning approach using UNet architecture. The UNet architecture was implemented using the TensorFlow deep learning framework and was trained to perform object detection and semantic segmentation.</p>
                <p>During training, the network was optimized by minimizing a loss function using the Adam optimizer. We used class weights to handle the imbalanced dataset, assigning higher weights to under-represented classes.</p>

                <h2>Results</h2>
                <figure>
                    <img src="images/3dobject/loss.png" alt="Training Loss">
                    <figcaption>Training and Validation Loss curves</figcaption>
                </figure>

                <div class="image-grid cols-3">
                    <img src="images/3dobject/1.jpeg" alt="Result 1">
                    <img src="images/3dobject/results.jpg" alt="Results comparison">
                    <img src="images/3dobject/box.png" alt="Bounding box detection">
                </div>
                <p style="text-align: center; font-size: 0.875rem; color: var(--color-text-muted);">Left: LiDAR input, Center: Ground truth labels, Right: Model predictions</p>

                <h2>Discussion</h2>
                <p>Our approach achieves strong performance in 3D object detection, outperforming several baseline approaches. The use of lidar data offers several advantages over traditional 2D methods - lidar sensors generate 3D point cloud data using lasers, which allows for improved localization and orientation estimation of objects in dynamic environments.</p>
                <p>There are several potential applications in autonomous vehicles and robotics. In autonomous vehicles, accurate 3D object detection is critical for safe navigation and decision-making. In robotics, 3D object detection can be used for tasks such as grasping and manipulation of objects.</p>

                <div class="image-grid cols-3">
                    <img src="images/3dobject/1.png" alt="3D Visualization 1">
                    <img src="images/3dobject/2.png" alt="3D Visualization 2">
                    <img src="images/3dobject/3.png" alt="3D Visualization 3">
                </div>
                <p style="text-align: center; font-size: 0.875rem; color: var(--color-text-muted);">Predictions reprojected into 3D space and overlaid with camera images</p>
            </div>
        </div>
    </main>

    <footer class="footer">
        <div class="container">
            <div class="footer-content">
                <div class="footer-brand">
                    <span class="footer-logo">KP</span>
                    <p class="footer-tagline">Building the future of AI-powered design</p>
                </div>
                <div class="footer-links">
                    <a href="index.html#about">About</a>
                    <a href="index.html#projects">Work</a>
                    <a href="index.html#research">Research</a>
                    <a href="index.html#writing">Writing</a>
                    <a href="index.html#contact">Contact</a>
                </div>
            </div>
            <div class="footer-bottom">
                <p>&copy; 2026 Kishore Pagidi. All rights reserved.</p>
            </div>
        </div>
    </footer>

    <script src="assets/js/app.js"></script>
</body>
</html>
